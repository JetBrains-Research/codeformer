GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/tim/anaconda3/envs/JetNN/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/tim/JetNN/jetnn/runners/wandb/run-20230706_151907-oc2f6dqp/files exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6]
  | Name     | Type                         | Params
----------------------------------------------------------
0 | _encoder | MethodNameTransformerEncoder | 76.7 M
1 | _decoder | MethodNameTransformerDecoder | 85.2 M
2 | _metrics | MetricCollection             | 0
3 | _loss    | SequenceCrossEntropyLoss     | 0
----------------------------------------------------------
161 M     Trainable params
0         Non-trainable params
161 M     Total params
647.578   Total estimated model params size (MB)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19400/19400 [00:00<00:00, 367633.83it/s]
  0%|                                                                                                                                                                                                                                                 | 0/19400 [00:00<?, ?it/s]
/home/tim/anaconda3/envs/JetNN/lib/python3.11/site-packages/torch/nn/modules/transformer.py:296: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)s]
  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)
/home/tim/anaconda3/envs/JetNN/lib/python3.11/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/home/tim/anaconda3/envs/JetNN/lib/python3.11/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
Sanity Checking DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.54it/s]
val
---------------
loss = 10.74
f1 = 0.0
precision = 0.0
recall = 0.0
chrf = 8.5
Epoch 0:   0%|                                                                                                                                                                                                                                        | 0/11545 [00:00<?, ?it/s]

Epoch 0:   0%|                                                                                                                                                                                             | 5/11545 [00:03<2:33:05,  1.26it/s, loss=9.78, v_num=6dqp, f1=0.000]
/home/tim/anaconda3/envs/JetNN/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:234: UserWarning: You called `self.log('train/precision', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.














































Epoch 0:   3%|█████▏                                                                                                                                                                                       | 320/11545 [01:36<56:18,  3.32it/s, loss=4.62, v_num=6dqp, f1=0.359]
/home/tim/anaconda3/envs/JetNN/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10664/10664 [00:00<00:00, 571370.91it/s]
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbe47a6c400>                                                                                                                                                             | 0/10664 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/tim/anaconda3/envs/JetNN/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    self._shutdown_workers()
  File "/home/tim/anaconda3/envs/JetNN/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1409, in _shutdown_workers
    if not self._shutdown:
           ^^^^^^^^^^^^^^

Testing: 0it [00:00, ?it/s]                                                                                                                                                                                | 321/11545 [01:36<56:18,  3.32it/s, loss=4.67, v_num=6dqp, f1=0.203]