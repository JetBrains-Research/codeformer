#defaults:
#  - opt: adamw
#  # - override hydra/launcher: joblib
#  - _self_

name: ???

epochs: 100
seed: 31
weight_decay: 0.0
learning_rate: 1e-4
accumulated_batch_size: 128
scheduler: null
warmup_part: 0.03

dataset_name: wikitext2raw
max_text_tokens: 1048576 # 2 ** 20
max_chunk_size: 14
num_context_chunks: 1
max_chunks_number: 32
num_previous_chunks: 1
min_tokens: 1
min_chunks: 1
num_workers: 8
prefetch_factor: 32
batch_size: 4

model_name: deberta_causal
tokenizer_name: null
base_model_name: microsoft/deberta-v3-small
random_init: false

dbg: false
verbose: true
train_steps: 64000
evaluate_every: epoch  # 1000 or 1 or any num step
use_batch_norm: false
full_batch_val: true


load_path: null
#load_path: /mnt/data/shared-data/codeformer/models/rand_init_codeformer.pt
