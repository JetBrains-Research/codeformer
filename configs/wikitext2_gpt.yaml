#defaults:
#  - opt: adamw
#  # - override hydra/launcher: joblib
#  - _self_

name: ???

epochs: 100
seed: 31
weight_decay: 0.0
learning_rate: 1e-4
batch_size: 128
micro_batch_size: 4

dataset_name: wikitext2raw
#max_text_tokens: 1048576  # 2 ** 20
max_text_tokens: 1022
max_chunk_size: 14
max_chunks_number: 32
min_tokens: 1
min_chunks: 1

num_workers_dl: 16
prefetch_factor_dl: 32

model_name: gpt2
base_model_name: null
random_init: false

dbg: false
verbose: true
train_steps: 64000
evaluate_every: epoch  # 1000 or 1 or any num step
use_batch_norm: false
full_batch_val: true


load_path: null
#load_path: /mnt/data/shared-data/codeformer/models/rand_init_codeformer.pt
