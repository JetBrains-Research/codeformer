#defaults:
#  - opt: adamw
#  # - override hydra/launcher: joblib
#  - _self_

name: ???

epochs: 100
seed: 31
weight_decay: 0.0
learning_rate: 1e-4
accumulated_batch_size: 128
scheduler: null
warmup_part: 0.03

#max_text_tokens: 1048576  # 2 ** 20
data_params:
  dataset_name: wikitext2raw
  max_text_tokens: 1022
  max_chunk_size: 14
  max_chunks_number: 32
  min_tokens: 1
  min_chunks: 1
  num_workers: 8
  prefetch_factor: 32
  batch_size: 4

model_name: gpt2
base_model_name: null
random_init: false

dbg: false
verbose: true
train_steps: 64000
evaluate_every: epoch  # 1000 or 1 or any num step
use_batch_norm: false
full_batch_val: true


load_path: null
#load_path: /mnt/data/shared-data/codeformer/models/rand_init_codeformer.pt
